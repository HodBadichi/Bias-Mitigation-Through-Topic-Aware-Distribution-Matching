{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from gensim import corpora\n",
    "### choose the callbacks classes to import\n",
    "from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def extract_lda_params(data_set):\n",
    "    \"\"\"\n",
    "    :param data_set: pandas dataframe object , each entry is a document\n",
    "    :return:\n",
    "          texts_data: list of lists where each inner-list represent a single document : [[dog,cat,mouse],[..],[..]]\n",
    "          corpus:Gensim corpus parameter for creating the LDA model\n",
    "          id2word:Gensim dictionary parameter for creating the LDA model\n",
    "    \"\"\"\n",
    "    texts_data = [str(x).split() for x in np.squeeze(data_set).values.tolist()]\n",
    "    id2word = corpora.Dictionary(texts_data)\n",
    "    # filter words which appear in less than 10 documents , or in more than 50% of the documents\n",
    "    id2word.filter_extremes(no_below=10, no_above=0.5)\n",
    "    corpus = [id2word.doc2bow(text) for text in texts_data]\n",
    "    return texts_data, corpus, id2word\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# The filename is the file that will be created with the log.\n",
    "# If the file already exists, the log will continue rather than being overwritten.\n",
    "from importlib import reload  # Not needed in Python 2\n",
    "import logging\n",
    "reload(logging)\n",
    "logging.basicConfig(filename=r'C:\\Users\\katac\\PycharmProjects\\NLP_project\\TopicModeling\\LDA\\src\\model_callbacks.log',\n",
    "                    format=\"%(asctime)s:%(levelname)s:%(message)s\",\n",
    "                    level=logging.NOTSET)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "train_data_path = r'C:\\Users\\katac\\PycharmProjects\\NLP_project\\TopicModeling\\LDA\\data\\clean_lda_train.csv'\n",
    "training_set = pd.read_csv(train_data_path, encoding='utf8')\n",
    "documents,corpus,dictionary = extract_lda_params(training_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Set up the callbacks loggers\n",
    "perplexity_logger = PerplexityMetric(corpus=corpus, logger='shell')\n",
    "convergence_logger = ConvergenceMetric(logger='shell')\n",
    "coherence_cv_logger = CoherenceMetric(corpus=corpus, logger='shell', coherence = 'c_v', texts = documents)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# List of the different iterations to try\n",
    "iterations = range(401,600,30)\n",
    "\n",
    "# The number of passes to use - could change depending on requirements\n",
    "passes = 1\n",
    "\n",
    "for iteration in iterations:\n",
    "\n",
    "    # Add text to logger to indicate new model\n",
    "    logging.debug(f'Start of model: {iteration} iterations')\n",
    "\n",
    "    # Create model - note callbacks argument uses list of created callback loggers\n",
    "    model = models.ldamodel.LdaModel(corpus=corpus,\n",
    "             id2word=dictionary,\n",
    "             num_topics=36,\n",
    "             eval_every=20,\n",
    "             passes=1,\n",
    "             iterations=iteration,\n",
    "            random_state=42,\n",
    "            callbacks=[convergence_logger, perplexity_logger, coherence_cv_logger])\n",
    "\n",
    "    # Add text to logger to indicate end of this model\n",
    "    logging.debug(f'End of model: {iteration} iterations')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "# Function to detect relevant numbers in log\n",
    "def find_doc_convergence(topic_num, iteration, log):\n",
    "    # Regex to bookend log for iteration - choose last occurrence\n",
    "    end_slice = re.compile(f\"End of model: .*?{iteration} iterations\")\n",
    "    end_matches = [end_slice.findall(l) for l in open(log)]\n",
    "    iteration_end = [i for i, x in enumerate(end_matches) if x]\n",
    "    iteration_end = iteration_end[-1]\n",
    "    start_slice = re.compile(f\"Start of model: .*?{iteration} iterations\")\n",
    "    start_matches = [start_slice.findall(l) for l in open(log)]\n",
    "    start_options = [i for i, x in enumerate(start_matches) if x]\n",
    "    start_options = [item for item in start_options if item < iteration_end]\n",
    "    iteration_start = max(start_options)\n",
    "    iteration_bookends = [iteration_start, iteration_end]\n",
    "    print(\"iteration_bookens is \")\n",
    "    print(iteration_bookends)\n",
    "    # Regex to find documents converged figures\n",
    "    p = re.compile(\"\\d+\\.\\d\")\n",
    "    matches = [ p.findall(l) for l in open(log)]\n",
    "    print(\"matches before slice is \\n\")\n",
    "    print(matches)\n",
    "    matches = matches[iteration_bookends[0]:iteration_bookends[1]]\n",
    "    print(\"matches after slice is \\n\")\n",
    "    print(matches)\n",
    "    matches = [m for m in matches if len(m) > 0]\n",
    "    # Unlist internal lists and turn into numbers\n",
    "    matches = [m for sublist in matches for m in sublist]\n",
    "    matches = [float(m) for m in matches]\n",
    "    return(matches)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda_10i50p/lda_10i50p.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:05<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration_bookens is \n",
      "[1, 5]\n",
      "matches before slice is \n",
      "\n",
      "[[], [], ['4.9'], ['203.2'], ['0.4'], [], [], ['4.9'], ['199.4'], ['0.4'], [], [], ['4.9'], ['199.4'], ['0.4'], []]\n",
      "matches after slice is \n",
      "\n",
      "[[], ['4.9'], ['203.2'], ['0.4']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (3) does not match length of index (1)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [109]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m models\u001B[38;5;241m.\u001B[39mldamodel\u001B[38;5;241m.\u001B[39mLdaModel\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlda_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mi50p/lda_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00miteration\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124mi50p.model\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      8\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(model\u001B[38;5;241m.\u001B[39mmetrics)\n\u001B[1;32m----> 9\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdocs_converged\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m find_doc_convergence(\u001B[38;5;241m5\u001B[39m, iteration, \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mUsers\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mkatac\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mPycharmProjects\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mNLP_project\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mTopicModeling\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mLDA\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124msrc\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mmodel_callbacks.log\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     10\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124miterations\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m iteration\n\u001B[0;32m     11\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtopics\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m5\u001B[39m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LDAmodeling\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3654\u001B[0m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\LDAmodeling\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001B[0m, in \u001B[0;36mDataFrame._set_item\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3823\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3824\u001B[0m \u001B[38;5;124;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[0;32m   3825\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3830\u001B[0m \u001B[38;5;124;03m    ensure homogeneity.\u001B[39;00m\n\u001B[0;32m   3831\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3832\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3834\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3835\u001B[0m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   3836\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   3837\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_extension_array_dtype(value)\n\u001B[0;32m   3838\u001B[0m     ):\n\u001B[0;32m   3839\u001B[0m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[0;32m   3840\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex):\n",
      "File \u001B[1;32m~\\PycharmProjects\\LDAmodeling\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4529\u001B[0m, in \u001B[0;36mDataFrame._sanitize_column\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m   4526\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m   4528\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[1;32m-> 4529\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4530\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sanitize_array(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\LDAmodeling\\venv\\lib\\site-packages\\pandas\\core\\common.py:557\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[1;34m(data, index)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[0;32m    555\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[1;32m--> 557\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    558\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    559\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    560\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    561\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    562\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Length of values (3) does not match length of index (1)"
     ]
    }
   ],
   "source": [
    "iterations = [ 10,15,20]\n",
    "\n",
    "all_metrics = pd.DataFrame()\n",
    "\n",
    "for iteration in tqdm.tqdm(iterations):\n",
    "    print(f\"lda_{iteration}i50p/lda_{iteration}i50p.model\")\n",
    "    model = models.ldamodel.LdaModel.load(f\"lda_{iteration}i50p/lda_{iteration}i50p.model\")\n",
    "    df = pd.DataFrame.from_dict(model.metrics)\n",
    "    df['docs_converged'] = find_doc_convergence(5, iteration, r'C:\\Users\\katac\\PycharmProjects\\NLP_project\\TopicModeling\\LDA\\src\\model_callbacks.log')\n",
    "    df['iterations'] = iteration\n",
    "    df['topics'] = 5\n",
    "\n",
    "    df = df.reset_index().rename(columns={'index': 'pass_num'})\n",
    "\n",
    "    all_metrics = pd.concat([all_metrics, df])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for metric in ['Coherence', 'Perplexity', 'Convergence', 'docs_converged']:\n",
    "\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(20, 7))\n",
    "\n",
    "    # Each plot to show results for all models with the same topic number\n",
    "    for i, topic_number in enumerate([5]):\n",
    "        filtered_topics = all_metrics[all_metrics['topics'] == topic_number]\n",
    "        for label, df in filtered_topics.groupby(['iterations']):\n",
    "            print(label)\n",
    "            df.plot(x='pass_num', y=metric, ax=axs, label=label)\n",
    "\n",
    "        axs.set_xlabel(f\"Pass number\")\n",
    "        axs.legend()\n",
    "        axs.set_ylim([all_metrics[metric].min() * 0.9, all_metrics[metric].max() * 1.1])\n",
    "\n",
    "    if metric == 'docs_converged':\n",
    "        fig.suptitle('Documents converged', fontsize=20)\n",
    "    else:\n",
    "        fig.suptitle(metric, fontsize=20)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}